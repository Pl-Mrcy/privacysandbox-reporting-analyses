{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differential privacy for online advertising"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prologue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, you will find a form of pseudo code we used to pull the data underlying the blog post Criteo published about k-thresholding.\n",
    "\n",
    "The raw data we base our analysis upon is stored in one Hadoop table (`logs.displays_clicks_sales`) with the following structure:\n",
    "\n",
    "| field name | data type | description |\n",
    "|------------|---------- |-------------|\n",
    "| day | DATE | Date at which the displays was printed |\n",
    "| environment | STRING | environment of the display (web, app, etc.) |\n",
    "| advertiser | STRING | Advertiser name|\n",
    "| publisher | STRING | Publisher name |\n",
    "| ad_size | [INT, INT] | the size of the ad (display height and width) |\n",
    "| device | STRING | The device the user is on (mobile, desktop, InApp..) |\n",
    "| displays | BIGINT | Number of displays |\n",
    "| clicks | BIGINT | Number of clicks |\n",
    "| sales | BIGINT | Number of sales |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statetments\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import criteopy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import laplace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partner data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pseudo query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "    SELECT\n",
    "        d.advertiser AS advertiser\n",
    "        , d.publisher AS publisher_domain\n",
    "        , d.ad_size as ad_size\n",
    "        , d.device as device\n",
    "        , SUM(d.displays) as nb_displays\n",
    "        , SUM(d.clicks) as nb_clicks\n",
    "        , SUM(d.sales) as nb_sales\n",
    "    FROM\n",
    "        logs.displays_clicks_sales d\n",
    "    WHERE\n",
    "        d.day ='2020-06-11'\n",
    "        AND d.advertiser = 'large_advertiser'\n",
    "    GROUP BY\n",
    "        d.advertiser\n",
    "        , d.publisher\n",
    "        , d.ad_size\n",
    "        , d.device\n",
    "        \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOme sanity checks\n",
    "# data_partner = get_query_result(query)\n",
    "data_partner.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_partner.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differential privacy - overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters for differential privacy\n",
    "# These numbers represent the maximum impact of one given user on the results of the querry. In our case, \n",
    "# they represent the maximum number of display, click, sales done by one user. We took the following values\n",
    "# arbitrarily,but some outliers (especially bots for instance) would strongly increase these number.\n",
    "delta_f_dict = {}\n",
    "delta_f_dict['nb_displays'] = 20\n",
    "delta_f_dict['nb_clicks'] = 3\n",
    "delta_f_dict['nb_sales'] = 1\n",
    "\n",
    "#This number represent the privacy budget. The higher, the more accurate the answer, but the less privacy preservation\n",
    "epsilon_privacy = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add Laplace noise\n",
    "\n",
    "\n",
    "def add_noise_to_stat(delta_f, epsilon_privacy):\n",
    "    '''\n",
    "    This function return a random noise from the laplace distribution with the right parameter\n",
    "    in order to ensure differential privacy\n",
    "    '''\n",
    "    return np.random.laplace(scale = delta_f / epsilon_privacy)\n",
    "\n",
    "def add_noise_to_stat_percentile(delta_f, epsilon_privacy, percentile):\n",
    "    '''\n",
    "    This function return a percentile of the laplacian noise.  \n",
    "    '''\n",
    "    return laplace(scale = delta_f / epsilon_privacy).ppf(percentile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noisy_sum(delta_f, epsilon_privacy):\n",
    "    '''\n",
    "    This function return the sum of a KPI with the right level of noise\n",
    "    '''\n",
    "    def sum_with_noise(x):\n",
    "        return np.sum(x) + add_noise_to_stat(delta_f, epsilon_privacy)\n",
    "    return sum_with_noise\n",
    "\n",
    "def sum_with_precentile_noise(delta_f, epsilon_privacy, percentile):\n",
    "    '''\n",
    "    This function return the sum of a KPI with the percentile noise\n",
    "    '''\n",
    "    percentile = add_noise_to_stat_percentile(delta_f, epsilon_privacy, percentile)\n",
    "    def precentile_sum_with_noise(x):\n",
    "        return np.sum(x) + percentile\n",
    "    return precentile_sum_with_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpi_of_interest = ['nb_displays', 'nb_clicks', 'nb_sales']\n",
    "aggregation_level = ['day']\n",
    "data_aggregated= data_partner.groupby(aggregation_level).agg(\n",
    "    {kpi: [('Actual_Value', np.sum), \n",
    "           ('TURTLEDOVE_value', noisy_sum(delta_f_dict[kpi], epsilon_privacy))] \n",
    "     for kpi in kpi_of_interest})\n",
    "\n",
    "for kpi in kpi_of_interest:\n",
    "    data_aggregated[(kpi, 'error (%)')] = 100 * (data_aggregated[(kpi, 'TURTLEDOVE_value')] / data_aggregated[(kpi, 'Actual_Value')] -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aggregated[kpi_of_interest].style.set_precision(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differential privacy - per domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpi_of_interest = ['nb_displays', 'nb_clicks', 'nb_sales']\n",
    "aggregation_level = ['day', 'publisher_domain']\n",
    "data_domain= data_partner.groupby(aggregation_level).agg(\n",
    "    {kpi: [('Actual_Value', np.sum), \n",
    "           ('TURTLEDOVE_value', noisy_sum(delta_f_dict[kpi], epsilon_privacy))] \n",
    "     for kpi in kpi_of_interest})\n",
    "for kpi in kpi_of_interest:\n",
    "    data_domain[(kpi, 'error (%)')] = 100 * (data_domain[(kpi, 'TURTLEDOVE_value')] / data_domain[(kpi, 'Actual_Value')] -1)\n",
    "\n",
    "row_to_return = [1,10,100,1000]\n",
    "data_domain[kpi_of_interest].sort_values(by=('nb_displays', 'Actual_Value'), ascending=False).iloc[row_to_return,:].style.set_precision(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differential privacy - per domain - with confidence intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Differential private reporting relies on noise. Before, we were generating noise on the fly. It is usefull to see confidence\n",
    "# intervals of the noise we are adding to the results. here we will go with a 90% confidence intervals (i.e [0.05,0.95])\n",
    "kpi_of_interest = ['nb_displays', 'nb_clicks', 'nb_sales']\n",
    "aggregation_level = ['day', 'publisher_domain']\n",
    "data_domain= data_partner.groupby(aggregation_level).agg(\n",
    "    {kpi: [('Actual_Value', np.sum), \n",
    "           ('TURTLEDOVE_value_down', sum_with_precentile_noise(delta_f_dict[kpi], epsilon_privacy, 0.05)),\n",
    "           ('TURTLEDOVE_value_up', sum_with_precentile_noise(delta_f_dict[kpi], epsilon_privacy, 0.95))\n",
    "          ] for kpi in kpi_of_interest})\n",
    "\n",
    "for kpi in kpi_of_interest:\n",
    "    data_domain[(kpi, 'confidence interval error (%)')] = 100 * (data_domain[(kpi, 'TURTLEDOVE_value_up')] / data_domain[(kpi, 'TURTLEDOVE_value_down')] -1)\n",
    "\n",
    "row_to_return = [1, 10, 100, 1000]\n",
    "data_domain[kpi_of_interest].sort_values(by=('nb_displays', 'Actual_Value'), ascending=False).iloc[row_to_return,:].style.set_precision(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
